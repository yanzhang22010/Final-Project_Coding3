# Final-Project_Coding3

## Chapter 1: Project Introduction

#### 1. Objective:
The goal of this project is to generate butterfly images using different GAN methods. Two high-level libraries, fastai and torchgan, both built on PyTorch, are utilized. The fastai library employs the WGAN algorithm from the GAN family, while torchgan utilizes DCGAN. By training models with different libraries, we can evaluate their performance.

#### 2. Algorithm References:

For fastai, refer to the official API documentation at: https://docs.fast.ai/vision.gan.html
For torchgan, refer to the official API documentation at: https://torchgan.readthedocs.io/en/latest/

#### 3. Dataset Source:
The dataset used for this project is obtained from Kaggle: https://www.kaggle.com/datasets/leerocky/butterfly

#### 4. Model Evaluation Method:
The Fréchet Inception Distance (FID) is used for model evaluation. More information about FID can be found at: https://torch-fidelity.readthedocs.io/en/latest/usage_api.html

## Chapter 2: Generating Images with fastai

#### 1. Library Import:
Import the necessary libraries, including fastai and other related dependencies.

#### 2. Dataset Import:
Use the methods provided by fastai to import the images.

#### 3. Image Visualization:
Randomly display nine existing butterfly images.

#### 4. Model Definition:
Define the WGAN model based on the API documentation.

#### 5. Model Training:
Adjust the learning rate and number of training iterations. In this case, increasing the number of iterations to 400 and further lowering the learning rate is necessary to generate high-quality butterfly images.

#### 6. Training Results:
After 400 iterations of training, the generator and discriminator losses have reached a very low level. Continuing the training with more iterations should lead to better results.

#### 7. Results Visualization:
Randomly display nine generated butterfly images.

#### 8. Image Generation:
Generate 128 butterfly images using the generator.

#### 9. Image Packaging:
Package the images into a .tgz file for convenient downloading and future use.

#### Summary
The model definition and training in this section mostly follow the official API documentation. However, improvements have been made to the training iterations and loss rates. The image generation and packaging parts have been adjusted based on various blog references.

## Chapter 3: Generating Images with torchgan

#### 1. Library Installation:
Install the torchgan module on Kaggle using the command "pip install torchgan".

#### 2. Library Import:
Import the necessary libraries, including torchgan and other related dependencies.

#### 3. Dataset Import:
For this section, the official example dataset in torchgan, CIFAR10, is not suitable. Various attempts were made to import the dataset, including using the DataBlock approach from fastai, but compatibility issues were encountered.

· First Attempt: Importing images using the DataBlock approach from fastai was successful, but the resulting data type did not match the requirements of torchgan.
· Second Attempt: Attempted to rewrite the import function based on online resources but was unsuccessful.
· Multiple attempts were made, but the details are omitted for brevity.
· Nth Attempt: Discovered the ImageFolder method in torchvision.datasets, which allowed importing the dataset images and performing the training process successfully. Reference blog: https://blog.csdn.net/weixin_43135178/article/details/115139178

#### 4. Model Definition and Training:
Follow the API documentation to define and train the model. The number of training iterations is also set to 400, consistent with the previous method. In order to suppress excessive printing during training, the %%capture magic command is used. Reference: https://www.zhihu.com/question/264396121

#### 5. Results Visualization:
During the training process, torchgan generates a set of images at each iteration. Matplotlib is used to compare the original images with the generated images.

#### 6. Image Generation:
Generate 128 butterfly images using the generator (similar to the fastai method).

#### 7. Image Packaging:
Package the images into a .tgz file, following a similar approach to the fastai method, for easy downloading and future use.

#### Summary:
The model definition and training in this section mostly follow the official API documentation. The number of training iterations matches the previous method. Difficulties were encountered in importing the dataset and visualizing images, but they were eventually overcome. The image generation and packaging process is similar to the previous method.

## Chapter 4: Model Comparison and Evaluation

#### 1. Using the FID metric mentioned in the blog https://blog.csdn.net/qq_40608730/article/details/110546612 to evaluate the quality of images generated by the two models.

#### 2. After searching, a ready-to-use library called "pytorch_fid" is found for calculating FID score. Follow the calculation method mentioned in the blog https://blog.csdn.net/aaatomaaa/article/details/129744348.

#### 3. When reusing the method, errors are encountered. It is found that the "transform" parameter is unexpected and is removed.

#### 4. After removing it, errors related to missing "dims" and "device" parameters are encountered. Assign values to these parameters based on previous knowledge during training.

#### 5. Even after resolving those errors, the calculations still fail. Through a blog https://github.com/toshas/torch-fidelity/issues/45, it is discovered that the "pytorch_fid" library is outdated and problematic, and a new library called "fidelity" is recommended.

#### 6. Find the API documentation for "fidelity" and replace some parameters to adapt to the current models: https://torch-fidelity.readthedocs.io/en/latest/usage_api.html

#### 7. After making the replacements, an error is still present. The blog https://github.com/toshas/torch-fidelity/issues/45 provides insights into the issue. It is due to the small number of generated dataset images, which is less than the default parameter of 1000. Adjust the "kid_subset_size" parameter to the number of generated images (128) and try again.

#### 8. The problem was solved and the two generated images were scored.

#### 9. Finally, the problem is resolved, and the FID scores for the two models' generated images are calculated. The FID scores for fastai's WGAN model and torchgan's DCGAN model are 165 and 212, respectively. Therefore, the images generated by fastai's WGAN model have a higher similarity.

Note: The code was messy during the evaluation process, but it was cleaned up afterward.
